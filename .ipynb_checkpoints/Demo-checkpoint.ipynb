{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR_ARCC: Dual Accuracy-quality-driven Prediction Intervals\n",
    "\n",
    "We created a synthetic dataset with varying PI widths that consists of a sinusoid with Gaussian noise.\n",
    "Specifically, the dataset contains 1000 points which were generated using the equation $y = 5 \\, \\text{cos}(x) + 10 + \\epsilon$, where $x \\in [-5, 5]$ and $\\epsilon$ is a Gaussian noise whose amplitude depends on $x$: $\\epsilon = (2 \\, \\text{cos}(1.2 \\, x) + 2) \\, g$ and $g \\sim \\mathcal{N}(0, 1)$.  \n",
    "\n",
    "For these experiments, we used a feed-forward neural network (FNN) with two hidden layers with 100 nodes each.\n",
    "$5\\times2$-fold cross-validation was used to train and evaluate all networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from PIGenerator import PIGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1: AR_ARCC**\n",
    "\n",
    "The target-estimation network $f$ is trained to generate accurate estimates, so that its parameteres $\\theta_f$ are obtained as:\n",
    "\n",
    "$\\boldsymbol{\\theta}_f = \\; \\underset{\\boldsymbol{\\theta_f}}{\\text{argmin}} \\ MSE_{est}.$\n",
    "\n",
    "The PI-generation NN is trained using our AR_ARCC loss function:\n",
    "\n",
    "$Loss_{AR_ARCC} = MPIW_{penalty} + \\lambda \\, C$\n",
    "\n",
    "where:\n",
    "* $MPIW_{penalty} = \\frac{1}{N} \\sum_{i=1}^{N} (|\\hat{y}^u_i - \\hat{y}_i| + |\\hat{y}_i - \\hat{y}^\\ell_i|)$ is a penalty \n",
    "term that quantifies the width of the PI as the sum of the distance between the upper bound and the target estimate and \n",
    "the distance between the lower bound and the target estimate,\n",
    "* $C = e^{\\xi - d_u} + e^{\\xi - d_\\ell} + e^{-\\sum_{i=1}^N(\\hat{y}^u_i - \\hat{y}^\\ell_i) / N}$ is a constraint that assures\n",
    "  PI interity. Here, $d_u = \\sum_{i=1}^N(\\hat{y}^u_i - \\hat{y}_i) / N$ and $d_\\ell = \\sum_{i=1}^N(\\hat{y}_i - \\hat{y}^\\ell_i) / N$\n",
    "  are the mean differences between the PI bounds and the target estimates, and \n",
    "$\\xi = \\text{max}(| \\hat{\\textbf{Y}}^b - \\textbf{Y}^b|)$ ($\\hat{\\textbf{Y}}^b = \\{ \\hat{y}_1, \\dots , \\hat{y}_N \\}$) is\n",
    "the maximum distance between a target estimate and its corresponding target value within the batch\n",
    "* $\\lambda$ is a self-adaptive coefficient that controls the relative importance of both objectives.\n",
    "\n",
    "Note that $\\lambda$ is adapted throughout the learning process automatically as follows:\n",
    "\n",
    "$\\lambda^{(t)} = \\lambda^{(t - 1)} + \\alpha \\cdot \\mathcal{C},$\n",
    "\n",
    "where $\\lambda^{(t)}$ denotes the value of the coefficient $\\lambda$ at the $t$-th iteration (we consider that $\\lambda^{(0)}=1$), and $\\alpha$ is a tunable learning rate.\n",
    "\n",
    "In this experiment, we use $\\alpha=0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Using 10x1 cross-validation for this dataset\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(series_decomp(\n  (moving_avg): moving_avg(\n    (avg): AvgPool1d(kernel_size=(24,), stride=(1,), padding=(0,))\n  )\n), dtype=object) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m predictor \u001b[38;5;241m=\u001b[39m PIGenerator(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYacht\u001b[39m\u001b[38;5;124m'\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAR_ARCC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m cvmse1, cvmpiw1, cvpicp1 \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrossval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m10x1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprintProcess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anew\\PredictionIntervals\\PIGenerator.py:104\u001b[0m, in \u001b[0;36mPIGenerator.train\u001b[1;34m(self, crossval, batch_size, epochs, alpha_, printProcess)\u001b[0m\n\u001b[0;32m    102\u001b[0m ntrain \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# 循环访问每个分区\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m first, second \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ntrain \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m crossval \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10x1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;66;03m# 使用 kfold.split 获取训练和测试映像的列表\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\c2-pytorch\\lib\\site-packages\\sklearn\\model_selection\\_split.py:342\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m        The testing set indices for that split.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\c2-pytorch\\lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\c2-pytorch\\lib\\site-packages\\sklearn\\utils\\validation.py:394\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    395\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\c2-pytorch\\lib\\site-packages\\sklearn\\utils\\validation.py:394\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    395\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\c2-pytorch\\lib\\site-packages\\sklearn\\utils\\validation.py:335\u001b[0m, in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 335\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    336\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleton array \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m cannot be considered a valid collection.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m x\n\u001b[0;32m    337\u001b[0m         )\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;66;03m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array array(series_decomp(\n  (moving_avg): moving_avg(\n    (avg): AvgPool1d(kernel_size=(24,), stride=(1,), padding=(0,))\n  )\n), dtype=object) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "predictor = PIGenerator(dataset='Yacht', method='AR_ARCC')\n",
    "cvmse1, cvmpiw1, cvpicp1 = predictor.train(crossval='10x1', batch_size=512, epochs=4500, alpha_=0.005, printProcess=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2: QD+**\n",
    "\n",
    "Train an ensemble of 5 FNNs using the [QD+](https://arxiv.org/abs/2007.09670) loss function:\n",
    "\n",
    "$Loss_{QD+} = (1 - \\lambda_1) (1 - \\lambda_2) MPIW_{capt}  + \\lambda_1 (1 - \\lambda_2) \\max(0, (1 - \\alpha) - PICP) ^ 2 + \\lambda_2 \\, MSE_{est} + \\frac{\\xi}{N} \\sum_{i=1}^N \\left[ \\max(0, (\\hat{y}^u_i - \\hat{y}_i) + \\max(0, (\\hat{y}_i - \\hat{y}^\\ell_i) \\right]$\n",
    "\n",
    "The PIs generated by the ensemble are aggregated using a split normal mixture.\n",
    "\n",
    "In this experiment, we use $\\lambda_1=0.6$ and $\\lambda_2=0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Using 10x1 cross-validation for this dataset\n",
      "\n",
      "******************************\n",
      "Training fold: 1\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [01:59<00:00, 25.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [01:57<00:00, 25.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [01:57<00:00, 25.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [01:54<00:00, 26.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [01:55<00:00, 25.97it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m predictor \u001b[38;5;241m=\u001b[39m PIGenerator(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBoston\u001b[39m\u001b[38;5;124m'\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQD-Ens\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m cvmse2, cvmpiw2, cvpicp2 \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrossval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m10x1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mprintProcess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anew\\PredictionIntervals\\PIGenerator.py:117\u001b[0m, in \u001b[0;36mPIGenerator.train\u001b[1;34m(self, crossval, batch_size, epochs, alpha_, printProcess)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# 在验证集“MC 样本”时间上运行模型并计算 PI 和指标\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# AR_ARCC已经在“trainFold”中执行验证和聚合\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAR_ARCC\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m--> 117\u001b[0m     [mse, PICP, MPIW, ypred, y_u, y_l] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPERFORMANCE AFTER AGGREGATION:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal MSE: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(mse) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Val PICP: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(PICP) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Val MPIW: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(MPIW))\n",
      "File \u001b[1;32mD:\\Anew\\PredictionIntervals\\PIGenerator.py:220\u001b[0m, in \u001b[0;36mPIGenerator.calculate_metrics\u001b[1;34m(self, Xval, Yval, maxs, mins, filepath)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mloadModel(filepath[mi])  \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# 使用经过训练的模型获取输出。MC_samples设置为 1，因为它们仅使用 1 个正向传递\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m     yout[:, :, mi] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluateFoldUncertainty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalxn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mmaxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mMC_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQD\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# QD aggregation\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# 获取 upper and lower bounds\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     y_u \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(yout[:, \u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.96\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(yout[:, \u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "predictor = PIGenerator(dataset='Power', method='QD+')\n",
    "cvmse2, cvmpiw2, cvpicp2 = predictor.train(crossval='10x1', batch_size=16, epochs=3000, alpha_=[0.6, 0.2], \n",
    "                                           printProcess=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 3: QD-Ens**  \n",
    "\n",
    "Train an ensemble of 5 FNNs using the [QD-Ens](https://arxiv.org/abs/1802.07167) loss function:\n",
    "\n",
    "$Loss_{QD} = MPIW_{capt}  + \\delta \\, \\frac{N}{\\alpha (1 - \\alpha)} \\max(0, (1 - \\alpha) - PICP) ^ 2$\n",
    "\n",
    "In this experiment, we use $\\delta=0.055$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Using 10x1 cross-validation for this dataset\n",
      "\n",
      "******************************\n",
      "Training fold: 1\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:45<00:00,  7.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:39<00:00,  7.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:47<00:00,  7.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:42<00:00,  7.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:42<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.04098677635192871 seconds to execute this batch\n",
      "PERFORMANCE AFTER AGGREGATION:\n",
      "Val MSE: 29.666295260058302 Val PICP: 0.9902912974357605 Val MPIW: 47.51245880126953\n",
      "\n",
      "******************************\n",
      "Training fold: 2\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:42<00:00,  7.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:42<00:00,  7.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:43<00:00,  7.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:38<00:00,  7.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:45<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.04411935806274414 seconds to execute this batch\n",
      "PERFORMANCE AFTER AGGREGATION:\n",
      "Val MSE: 19.841788635727173 Val PICP: 1.0 Val MPIW: 47.795265197753906\n",
      "\n",
      "******************************\n",
      "Training fold: 3\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:59<00:00,  7.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:51<00:00,  7.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:43<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.0382232666015625 seconds to execute this batch\n",
      "PERFORMANCE AFTER AGGREGATION:\n",
      "Val MSE: 19.551333145969732 Val PICP: 1.0 Val MPIW: 48.29792022705078\n",
      "\n",
      "******************************\n",
      "Training fold: 4\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:38<00:00,  7.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:43<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.03940701484680176 seconds to execute this batch\n",
      "PERFORMANCE AFTER AGGREGATION:\n",
      "Val MSE: 19.415222942019675 Val PICP: 1.0 Val MPIW: 47.68773651123047\n",
      "\n",
      "******************************\n",
      "Training fold: 5\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:39<00:00,  7.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:45<00:00,  7.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:43<00:00,  7.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:38<00:00,  7.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.03873300552368164 seconds to execute this batch\n",
      "PERFORMANCE AFTER AGGREGATION:\n",
      "Val MSE: 10.407694560717403 Val PICP: 1.0 Val MPIW: 48.01000213623047\n",
      "\n",
      "******************************\n",
      "Training fold: 6\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:43<00:00,  7.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:38<00:00,  7.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:40<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.04590415954589844 seconds to execute this batch\n",
      "PERFORMANCE AFTER AGGREGATION:\n",
      "Val MSE: 28.622245154466942 Val PICP: 1.0 Val MPIW: 47.73273849487305\n",
      "\n",
      "******************************\n",
      "Training fold: 7\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:42<00:00,  7.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:42<00:00,  7.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:41<00:00,  7.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.03846907615661621 seconds to execute this batch\n",
      "PERFORMANCE AFTER AGGREGATION:\n",
      "Val MSE: 12.739223369302888 Val PICP: 1.0 Val MPIW: 47.523433685302734\n",
      "\n",
      "******************************\n",
      "Training fold: 8\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:43<00:00,  7.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:40<00:00,  7.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:38<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.04590630531311035 seconds to execute this batch\n",
      "PERFORMANCE AFTER AGGREGATION:\n",
      "Val MSE: 16.275405030984874 Val PICP: 1.0 Val MPIW: 47.39982223510742\n",
      "\n",
      "******************************\n",
      "Training fold: 9\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:38<00:00,  7.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.0392916202545166 seconds to execute this batch\n",
      "PERFORMANCE AFTER AGGREGATION:\n",
      "Val MSE: 9.85717111577794 Val PICP: 1.0 Val MPIW: 47.935420989990234\n",
      "\n",
      "******************************\n",
      "Training fold: 10\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:38<00:00,  7.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:45<00:00,  7.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:39<00:00,  7.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:44<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.03696155548095703 seconds to execute this batch\n",
      "PERFORMANCE AFTER AGGREGATION:\n",
      "Val MSE: 20.080042798857296 Val PICP: 1.0 Val MPIW: 47.748939514160156\n"
     ]
    }
   ],
   "source": [
    "predictor = PIGenerator(dataset='Concrete', method='QD')\n",
    "cvmse3, cvmpiw3, cvpicp3 = predictor.train(crossval='10x1', batch_size=16, epochs=3000, alpha_=0.055, printProcess=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 4: MC-Dropout-PI**  \n",
    "\n",
    "Train a FNN using the MSE loss function. PIs are obtained by quantifying the model uncertainty through \n",
    "[MC-Dropout](https://arxiv.org/abs/1709.01907), coupled with estimating the data noise variance through an independent \n",
    "held-out validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Using 5x2 cross-validation for this dataset\n",
      "\n",
      "******************************\n",
      "Training fold: 1\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 2 is out of bounds for array of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m predictor \u001b[38;5;241m=\u001b[39m PIGenerator(dataset\u001b[38;5;241m=\u001b[39mname, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMCDropout\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m cvmse4, cvmpiw4, cvpicp4 \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrossval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m5x2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprintProcess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anew\\PredictionIntervals\\PIGenerator.py:107\u001b[0m, in \u001b[0;36mPIGenerator.train\u001b[1;34m(self, crossval, batch_size, epochs, alpha_, printProcess)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# Train the model using the current training-validation split\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_model()\n\u001b[1;32m--> 107\u001b[0m     _, _, _, mse, PICP, MPIW \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mprintProcess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprintProcess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43myscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmaxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmins\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Run the model over the validation set 'MC-samples' times and Calculate PIs and metrics\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAR_ARCC\u001b[39m\u001b[38;5;124m'\u001b[39m]:  \u001b[38;5;66;03m# AR_ARCC already performs validation and aggregation in \"trainFold\"\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anew\\PredictionIntervals\\models\\NNModel.py:294\u001b[0m, in \u001b[0;36mNNModel.trainFold\u001b[1;34m(self, Xtrain, Ytrain, Xval, Yval, batch_size, epochs, filepath, printProcess, yscale, alpha_)\u001b[0m\n\u001b[0;32m    292\u001b[0m     ypredtr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluateFoldUncertainty(valxn\u001b[38;5;241m=\u001b[39mXtrain, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(Xtrain), MC_samples\u001b[38;5;241m=\u001b[39msamples)\n\u001b[0;32m    293\u001b[0m     ypred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluateFoldUncertainty(valxn\u001b[38;5;241m=\u001b[39mXval, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(Xval), MC_samples\u001b[38;5;241m=\u001b[39msamples)\n\u001b[1;32m--> 294\u001b[0m     ypredtr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mypredtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m     ypred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(ypred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\c2-pytorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3437\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3438\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_mean(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3441\u001b[0m                       out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\c2-pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:167\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    163\u001b[0m arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[0;32m    165\u001b[0m is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m rcount \u001b[38;5;241m=\u001b[39m \u001b[43m_count_reduce_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m umr_any(rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    169\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of empty slice.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\c2-pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:76\u001b[0m, in \u001b[0;36m_count_reduce_items\u001b[1;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[0;32m     74\u001b[0m     items \u001b[38;5;241m=\u001b[39m nt\u001b[38;5;241m.\u001b[39mintp(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis:\n\u001b[1;32m---> 76\u001b[0m         items \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mshape[\u001b[43mmu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_axis_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# TODO: Optimize case when `where` is broadcast along a non-reduction\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# axis and full sum is more excessive than needed.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# guarded to protect circular imports\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstride_tricks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m broadcast_to\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 2 is out of bounds for array of dimension 2"
     ]
    }
   ],
   "source": [
    "predictor = PIGenerator(dataset=name, method='MCDropout')\n",
    "cvmse4, cvmpiw4, cvpicp4 = predictor.train(crossval='5x2', batch_size=8, epochs=1000, printProcess=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method Comparison**\n",
    "\n",
    "We perform a paired *t*-test at the 0.05 significance level and plot box plots for each metric (MPIW, MSE, and PICP).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cvmpiw2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmpiw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpicp\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      2\u001b[0m     cvAQD \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m metric \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m     cvQDp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m     cvQD \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m metric \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m     cvMC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m metric \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cvmpiw2'"
     ]
    }
   ],
   "source": [
    "for metric in ['mpiw', 'mse', 'picp']:\n",
    "    cvAQD = globals()['cv' + metric + '1']\n",
    "    cvQDp = globals()['cv' + metric + '2']\n",
    "    cvQD = globals()['cv' + metric + '3']\n",
    "    cvMC = globals()['cv' + metric + '4']\n",
    "    df = pd.DataFrame({'AQD': cvAQD, 'QD+': cvQDp, 'QD': cvQD, 'MC-Dropout-PI': cvMC})\n",
    "    ax = df[['AQD', 'QD+', 'QD', 'MC-Dropout-PI']].plot(kind='box', showmeans=True)\n",
    "    ax.tick_params(labelsize=9)\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "    # Perform t-test\n",
    "    print('Metric: ' + metric)\n",
    "    compqdp = stats.ttest_rel(df['AQD'], df['QD+'])\n",
    "    print('AQD vs. QD+. p-value = ' + str(compqdp.pvalue))\n",
    "    compqd = stats.ttest_rel(df['AQD'], df['QD'])\n",
    "    print('AQD vs. QD. p-value = ' + str(compqd.pvalue))\n",
    "    compmc = stats.ttest_rel(df['AQD'], df['MC-Dropout-PI'])\n",
    "    print('AQD vs. MC-Dropout-PI. p-value = ' + str(compmc.pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
